{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# --- Librerías estándar ---\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "# --- Configuración ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "# --- Librerías para manipulación de datos ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as req\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "# --- Visualización ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# --- Machine Learning ---\n",
    "## Modelos\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "## Modelos de Scikit-Learn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, RandomForestRegressor, StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "## Preprocesamiento y selección de características\n",
    "from sklearn.feature_selection import (\n",
    "    RFE, RFECV, SelectFromModel, SelectKBest, f_classif\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, MinMaxScaler, PowerTransformer, RobustScaler, StandardScaler\n",
    ")\n",
    "## Evaluación de modelos\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "## División de datos y optimización de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "# --- Balanceo de datos ---\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de 2000-01-01T00:00:00UTC a 2000-07-01T23:59:59UTC agregados correctamente.\n",
      "Datos de 2000-07-02T00:00:00UTC a 2000-12-31T23:59:59UTC agregados correctamente.\n",
      "Datos de 2001-01-01T00:00:00UTC a 2001-07-02T23:59:59UTC agregados correctamente.\n",
      "Datos de 2001-07-03T00:00:00UTC a 2002-01-01T23:59:59UTC agregados correctamente.\n",
      "Datos de 2002-01-02T00:00:00UTC a 2002-07-03T23:59:59UTC agregados correctamente.\n",
      "Datos de 2002-07-04T00:00:00UTC a 2003-01-02T23:59:59UTC agregados correctamente.\n",
      "Datos de 2003-01-03T00:00:00UTC a 2003-07-04T23:59:59UTC agregados correctamente.\n",
      "Datos de 2003-07-05T00:00:00UTC a 2004-01-03T23:59:59UTC agregados correctamente.\n",
      "Datos de 2004-01-04T00:00:00UTC a 2004-07-04T23:59:59UTC agregados correctamente.\n",
      "Datos de 2004-07-05T00:00:00UTC a 2005-01-03T23:59:59UTC agregados correctamente.\n",
      "Datos de 2005-01-04T00:00:00UTC a 2005-07-05T23:59:59UTC agregados correctamente.\n",
      "Datos de 2005-07-06T00:00:00UTC a 2006-01-04T23:59:59UTC agregados correctamente.\n",
      "Datos de 2006-01-05T00:00:00UTC a 2006-07-06T23:59:59UTC agregados correctamente.\n",
      "Datos de 2006-07-07T00:00:00UTC a 2007-01-05T23:59:59UTC agregados correctamente.\n",
      "Datos de 2007-01-06T00:00:00UTC a 2007-07-07T23:59:59UTC agregados correctamente.\n",
      "Datos de 2007-07-08T00:00:00UTC a 2008-01-06T23:59:59UTC agregados correctamente.\n",
      "Datos de 2008-01-07T00:00:00UTC a 2008-07-07T23:59:59UTC agregados correctamente.\n",
      "Datos de 2008-07-08T00:00:00UTC a 2009-01-06T23:59:59UTC agregados correctamente.\n",
      "Datos de 2009-01-07T00:00:00UTC a 2009-07-08T23:59:59UTC agregados correctamente.\n",
      "Datos de 2009-07-09T00:00:00UTC a 2010-01-07T23:59:59UTC agregados correctamente.\n",
      "Datos de 2010-01-08T00:00:00UTC a 2010-07-09T23:59:59UTC agregados correctamente.\n",
      "Datos de 2010-07-10T00:00:00UTC a 2011-01-08T23:59:59UTC agregados correctamente.\n",
      "Datos de 2011-01-09T00:00:00UTC a 2011-07-10T23:59:59UTC agregados correctamente.\n",
      "Datos de 2011-07-11T00:00:00UTC a 2012-01-09T23:59:59UTC agregados correctamente.\n",
      "Datos de 2012-01-10T00:00:00UTC a 2012-07-10T23:59:59UTC agregados correctamente.\n",
      "Datos de 2012-07-11T00:00:00UTC a 2013-01-09T23:59:59UTC agregados correctamente.\n",
      "Datos de 2013-01-10T00:00:00UTC a 2013-07-11T23:59:59UTC agregados correctamente.\n",
      "Datos de 2013-07-12T00:00:00UTC a 2014-01-10T23:59:59UTC agregados correctamente.\n",
      "Datos de 2014-01-11T00:00:00UTC a 2014-07-12T23:59:59UTC agregados correctamente.\n",
      "Datos de 2014-07-13T00:00:00UTC a 2015-01-11T23:59:59UTC agregados correctamente.\n",
      "Datos de 2015-01-12T00:00:00UTC a 2015-07-13T23:59:59UTC agregados correctamente.\n",
      "Datos de 2015-07-14T00:00:00UTC a 2016-01-12T23:59:59UTC agregados correctamente.\n",
      "Datos de 2016-01-13T00:00:00UTC a 2016-07-13T23:59:59UTC agregados correctamente.\n",
      "Datos de 2016-07-14T00:00:00UTC a 2017-01-12T23:59:59UTC agregados correctamente.\n",
      "Datos de 2017-01-13T00:00:00UTC a 2017-07-14T23:59:59UTC agregados correctamente.\n",
      "Datos de 2017-07-15T00:00:00UTC a 2018-01-13T23:59:59UTC agregados correctamente.\n",
      "Datos de 2018-01-14T00:00:00UTC a 2018-07-15T23:59:59UTC agregados correctamente.\n",
      "Datos de 2018-07-16T00:00:00UTC a 2019-01-14T23:59:59UTC agregados correctamente.\n",
      "Datos de 2019-01-15T00:00:00UTC a 2019-07-16T23:59:59UTC agregados correctamente.\n",
      "Datos de 2019-07-17T00:00:00UTC a 2020-01-15T23:59:59UTC agregados correctamente.\n",
      "Datos de 2020-01-16T00:00:00UTC a 2020-07-16T23:59:59UTC agregados correctamente.\n",
      "Datos de 2020-07-17T00:00:00UTC a 2021-01-15T23:59:59UTC agregados correctamente.\n",
      "Datos de 2021-01-16T00:00:00UTC a 2021-07-17T23:59:59UTC agregados correctamente.\n",
      "Datos de 2021-07-18T00:00:00UTC a 2022-01-16T23:59:59UTC agregados correctamente.\n",
      "Datos de 2022-01-17T00:00:00UTC a 2022-07-18T23:59:59UTC agregados correctamente.\n",
      "Datos de 2022-07-19T00:00:00UTC a 2023-01-17T23:59:59UTC agregados correctamente.\n",
      "Datos de 2023-01-18T00:00:00UTC a 2023-07-19T23:59:59UTC agregados correctamente.\n",
      "Datos de 2023-07-20T00:00:00UTC a 2024-01-18T23:59:59UTC agregados correctamente.\n",
      "Datos de 2024-01-19T00:00:00UTC a 2024-07-19T23:59:59UTC agregados correctamente.\n",
      "Datos de 2024-07-20T00:00:00UTC a 2025-01-18T23:59:59UTC agregados correctamente.\n",
      "Datos de 2025-01-19T00:00:00UTC a 2025-01-31T23:59:59UTC agregados correctamente.\n",
      "Proceso completo\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152262 entries, 0 to 152261\n",
      "Data columns (total 25 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   fecha        152262 non-null  object\n",
      " 1   indicativo   152262 non-null  object\n",
      " 2   nombre       152262 non-null  object\n",
      " 3   provincia    152262 non-null  object\n",
      " 4   altitud      152262 non-null  object\n",
      " 5   tmed         144526 non-null  object\n",
      " 6   prec         146267 non-null  object\n",
      " 7   tmin         144553 non-null  object\n",
      " 8   horatmin     144398 non-null  object\n",
      " 9   tmax         144539 non-null  object\n",
      " 10  horatmax     144437 non-null  object\n",
      " 11  velmedia     120601 non-null  object\n",
      " 12  sol          48224 non-null   object\n",
      " 13  presMax      80300 non-null   object\n",
      " 14  horaPresMax  80295 non-null   object\n",
      " 15  presMin      80300 non-null   object\n",
      " 16  horaPresMin  80293 non-null   object\n",
      " 17  hrMedia      141542 non-null  object\n",
      " 18  dir          117489 non-null  object\n",
      " 19  racha        117489 non-null  object\n",
      " 20  horaracha    117475 non-null  object\n",
      " 21  hrMax        108641 non-null  object\n",
      " 22  horaHrMax    108638 non-null  object\n",
      " 23  hrMin        108635 non-null  object\n",
      " 24  horaHrMin    108633 non-null  object\n",
      "dtypes: object(25)\n",
      "memory usage: 29.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# api_key\n",
    "#a partir de aqui es el codigo que descarga todos los registros desde el 1-1-2000\n",
    "# conf API\n",
    "configuration = swagger_client.Configuration()\n",
    "configuration.api_key['api_key'] = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJpcGhvbmVkZWRhbmllbEBnbWFpbC5jb20iLCJqdGkiOiJjZThiMzM4YS1mM2NhLTRkNDgtOTQ3Zi00NTUzMmZkNTNiY2QiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTczODUwMjQwNiwidXNlcklkIjoiY2U4YjMzOGEtZjNjYS00ZDQ4LTk0N2YtNDU1MzJmZDUzYmNkIiwicm9sZSI6IiJ9.-50vwaqb_nrSxCFkTqrg0MQt5dppbNAU2yDSmJEFjfU'\n",
    "api_instance = swagger_client.ValoresClimatologicosApi(swagger_client.ApiClient(configuration))\n",
    "\n",
    "# Parametros\n",
    "idema = '3200,3195,3196,3129,3191E,3170Y,3268C,3100B,3182Y,3110C,3191E,3126Y,3194Y,3266A,2462,3104Y,3338,3330Y,3125Y,3111D,3229Y,3343Y'  #estaciones meteorologicas\n",
    "fecha_inicio = datetime(2000, 1, 1)  \n",
    "fecha_fin_total = datetime(2025, 1, 31)  \n",
    "\n",
    "# creo dataFrame final\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "# bucle\n",
    "while fecha_inicio < fecha_fin_total:\n",
    "    fecha_fin = fecha_inicio + timedelta(days=182)  #  6 meses +o-\n",
    "    if fecha_fin > fecha_fin_total:\n",
    "        fecha_fin = fecha_fin_total  # ajuste si excede\n",
    "\n",
    "    # devolver a str\n",
    "    fecha_ini_str = fecha_inicio.strftime('%Y-%m-%dT00:00:00UTC')\n",
    "    fecha_fin_str = fecha_fin.strftime('%Y-%m-%dT23:59:59UTC')\n",
    "\n",
    "    try:\n",
    "        # API\n",
    "        api_response = api_instance.climatologas_diarias_(fecha_ini_str, fecha_fin_str, idema)\n",
    "        url = api_response.datos\n",
    "        response = req.get(url)\n",
    "        r = response.json()\n",
    "\n",
    "        df = pd.DataFrame(r)\n",
    "\n",
    "        # Concateno  el df\n",
    "        df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "\n",
    "        # guardar\n",
    "        df_total.to_csv(\"datos_climatologicos2.csv\", index=False)\n",
    "\n",
    "        print(f\"Datos de {fecha_ini_str} a {fecha_fin_str} agregados correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo datos de {fecha_ini_str} a {fecha_fin_str}: {e}\")\n",
    "\n",
    "    # avanzo la fecha de inicio\n",
    "    fecha_inicio = fecha_fin + timedelta(days=1)\n",
    "\n",
    "print(\"Proceso completo\")\n",
    "print(df_total.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
